---
apiVersion: v1
kind: Namespace
metadata:
  name: yugabyte
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: nodereader
  namespace: yugabyte
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: node-reader
rules:
  - apiGroups:
      - ""
    resources:
      - nodes
      - pods
    verbs:
      - get
      - list
      - watch
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: crb-read-nodes
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: node-reader
subjects:
  - kind: ServiceAccount
    name: nodereader
    namespace: yugabyte
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: yb-master
  namespace: yugabyte
data:
  init-yb.sh: |
    #!/bin/sh
    /home/yugabyte/bin/yb-master \
    --fs_data_dirs=/mnt/disk0,/mnt/disk1 \
    --rpc_bind_addresses=${HOSTNAME}.yb-masters.${NAMESPACE}.svc.cluster.local \
    --server_broadcast_addresses=${HOSTNAME}.yb-masters.${NAMESPACE}.svc.cluster.local:7100 \
    --webserver_interface=0.0.0.0 \
    --master_addresses=yb-master-0.yb-masters:7100,yb-master-1.yb-masters:7100,yb-master-2.yb-masters:7100 \
    --replication_factor=3 \
    --enable_ysql=true \
    --metric_node_name=${HOSTNAME} \
    --memory_limit_hard_bytes=7298088960 \
    --stderrthreshold=0 \
    --num_cpus=7 \
    --undefok=num_cpus,enable_ysql \
    --default_memory_limit_to_ram_ratio=0.85 \
    --placement_cloud=%CSP% \
    --placement_region=%REGION% \
    --placement_zone=%ZONE%\
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: yb-table-servers
  namespace: yugabyte
data:
  init-yb.sh: |
    #!/bin/sh
    /home/yugabyte/bin/yb-tserver \
    --fs_data_dirs=/mnt/disk0,/mnt/disk1 \
    --server_broadcast_addresses=${HOSTNAME}.yb-tservers.${NAMESPACE}.svc.cluster.local:9100 \
    --rpc_bind_addresses=${HOSTNAME}.yb-tservers.${NAMESPACE}.svc.cluster.local \
    --cql_proxy_bind_address=${HOSTNAME}.yb-tservers.${NAMESPACE}.svc.cluster.local \
    --webserver_interface=0.0.0.0 \
    --enable_ysql=true \
    --pgsql_proxy_bind_address=0.0.0.0:5433 \
    --tserver_master_addrs=yb-master-0.yb-masters:7100,yb-master-1.yb-masters:7100,yb-master-2.yb-masters:7100 \
    --metric_node_name=${HOSTNAME} \
    --memory_limit_hard_bytes=3649044480 \
    --stderrthreshold=0 \
    --num_cpus=1 \
    --undefok=num_cpus,enable_ysql \
    --placement_cloud=%CSP% \
    --placement_region=%REGION% \
    --placement_zone=%ZONE%\
---
apiVersion: v1
kind: Service
metadata:
  name: "yb-masters"
  namespace: yugabyte
  labels:
    app: "yb-master"
    service-type: "headless"
spec:
  clusterIP: None
  ports:
    - name: "http-ui"
      port: 7000
    - name: "tcp-rpc-port"
      port: 7100
  selector:
    app: "yb-master"
---
apiVersion: v1
kind: Service
metadata:
  name: "yb-tservers"
  namespace: yugabyte
  labels:
    app: "yb-tserver"
spec:
  clusterIP: None
  ports:
    - name: "http-ui"
      port: 9000
    - name: "http-ycql-met"
      port: 12000
    - name: "http-yedis-met"
      port: 11000
    - name: "http-ysql-met"
      port: 13000
    - name: "tcp-rpc-port"
      port: 9100
    - name: "tcp-yedis-port"
      port: 6379
    - name: "tcp-yql-port"
      port: 9042
    - name: "tcp-ysql-port"
      port: 5433
  selector:
    app: "yb-tserver"
---
apiVersion: batch/v1
kind: Job
metadata:
  name: setup-redis-table
  namespace: yugabyte
spec:
  ttlSecondsAfterFinished: 0
  template:
    spec:
      containers:
        - name: main
          image: "yugabytedb/yugabyte:2.6.1.0-b49"
          command:
            - "sh"
            - "-c"
            - |
              while true; do
                state=$(/home/yugabyte/bin/yb-admin -master_addresses "yb-master-0.yb-masters:7100, yb-master-1.yb-masters:7100, yb-master-2.yb-masters:7100" list_all_masters)
                if [[ $state =~ 'ALIVE' ]]; then
                  break
                fi
                sleep .5
              done
              sleep 30
              /home/yugabyte/bin/yb-admin --master_addresses "yb-master-0.yb-masters:7100, yb-master-1.yb-masters:7100, yb-master-2.yb-masters:7100" setup_redis_table
      restartPolicy: Never
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: "yb-master"
  namespace: "yugabyte"
  labels:
    app: "yb-master"
spec:
  serviceName: "yb-masters"
  podManagementPolicy: Parallel
  replicas: 3
  volumeClaimTemplates:
    - metadata:
        name: datadir0
      spec:
        accessModes:
          - "ReadWriteOnce"
        resources:
          requests:
            storage: 10Gi
    - metadata:
        name: datadir1
      spec:
        accessModes: [ "ReadWriteOnce" ]
        resources:
          requests:
            storage: 10Gi
  updateStrategy:
    type: RollingUpdate
    rollingUpdate:
      partition: 0
  selector:
    matchLabels:
      app: "yb-master"
  template:
    metadata:
      labels:
        app: "yb-master"
    spec:
      serviceAccountName: nodereader
      initContainers:
        - name: init-topology
          image: "photon:3.0-20210108"
          imagePullPolicy: IfNotPresent
          command:
            - "sh"
            - "-c"
            - |
              cp /cm-yb/init-yb.sh /tmp/env/init-yb.sh
              curl -L'#' -o /usr/bin/jq https://github.com/stedolan/jq/releases/download/jq-1.5/jq-linux64 && chmod +x /usr/bin/jq
              export CSP="AWS"
              export REGION=$(curl -sv --cacert /var/run/secrets/kubernetes.io/serviceaccount/ca.crt -H "Authorization: Bearer $(cat /var/run/secrets/kubernetes.io/serviceaccount/token)" https://$KUBERNETES_PORT_443_TCP_ADDR:$KUBERNETES_PORT_443_TCP_PORT/api/v1/nodes/$K8S_NODE | jq '.metadata.labels."topology.kubernetes.io/region"')
              export ZONE="on-demand"
              echo "{ \"csp\":$CSP, \"region\":$REGION, \"zone\":$ZONE }" >> /tmp/env/topology.json
              sed -i "s/%CSP%/$CSP/g" /tmp/env/init-yb.sh
              sed -i "s/%REGION%/$REGION/g" /tmp/env/init-yb.sh
              sed -i "s/%ZONE%/$ZONE/g" /tmp/env/init-yb.sh
          env:
            - name: K8S_NODE
              valueFrom:
                fieldRef:
                  fieldPath: spec.nodeName
          volumeMounts:
            - name: cm-yb
              mountPath: /cm-yb
            - name: config-shared-volume
              mountPath: /tmp/env
      containers:
        - name: "yb-master"
          image: "yugabytedb/yugabyte:2.6.1.0-b49"
          imagePullPolicy: IfNotPresent
          resources:
            requests:
              cpu: 7000m
              memory: 7Gi
          env:
            - name: POD_IP
              valueFrom:
                fieldRef:
                  fieldPath: status.podIP
            - name: HOSTNAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
          # resources:
          # core dumps are collected to workingDir if
          # kernel.core_pattern is set to a relative path like
          # core.%e.%p.%t ref:
          # https://github.com/yugabyte/charts/issues/11
          workingDir: "/mnt/disk0/cores"
          command:
            #command entrypoint is taken from mounted volume written to by init container.
            #init container copies template from configmap yb-master-servers and modifies placeholders
            #for csp, region, and zone
            - "sh"
            - "-c"
            - |
              /tmp/env/init-yb.sh
          ports:
            - containerPort: 7000
              name: "http-ui"
            - containerPort: 7100
              name: "tcp-rpc-port"
          volumeMounts:
            - name: datadir0
              mountPath: /mnt/disk0
            - name: datadir1
              mountPath: /mnt/disk1
            - name: config-shared-volume
              mountPath: /tmp/env/
      volumes:
        - name: config-shared-volume
          emptyDir: {}
        - name: cm-yb
          configMap:
            name: yb-master
            defaultMode: 0755
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: "yb-tserver"
  namespace: "yugabyte"
  labels:
    app: "yb-tserver"
spec:
  serviceName: "yb-tservers"
  podManagementPolicy: Parallel
  replicas: 3
  volumeClaimTemplates:
    - metadata:
        name: datadir0
      spec:
        accessModes: [ "ReadWriteOnce" ]
        resources:
          requests:
            storage: 100Gi
    - metadata:
        name: datadir1
      spec:
        accessModes:
          - "ReadWriteOnce"
        resources:
          requests:
            storage: 100Gi
  updateStrategy:
    type: RollingUpdate
    rollingUpdate:
      partition: 0
  selector:
    matchLabels:
      app: "yb-tserver"
  template:
    metadata:
      labels:
        app: "yb-tserver"
    spec:
      serviceAccountName: nodereader
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            - labelSelector:
                matchExpressions:
                  - key: app
                    operator: In
                    values:
                      - "yb-tserver"
              topologyKey: "kubernetes.io/hostname"
      initContainers:
        - name: init-topology
          image: "photon:3.0-20210108"
          imagePullPolicy: IfNotPresent
          command:
            - "sh"
            - "-c"
            - |
              cp /yb-table-servers/init-yb.sh /tmp/env/init-yb.sh
              curl -L'#' -o /usr/bin/jq https://github.com/stedolan/jq/releases/download/jq-1.5/jq-linux64 && chmod +x /usr/bin/jq
              export CSP="AWS"
              export REGION=$(curl -sv --cacert /var/run/secrets/kubernetes.io/serviceaccount/ca.crt -H "Authorization: Bearer $(cat /var/run/secrets/kubernetes.io/serviceaccount/token)" https://$KUBERNETES_PORT_443_TCP_ADDR:$KUBERNETES_PORT_443_TCP_PORT/api/v1/nodes/$K8S_NODE | jq '.metadata.labels."topology.kubernetes.io/region"')
              export ZONE="on-demand"
              echo "{ \"csp\":$CSP, \"region\":$REGION, \"zone\":$ZONE }" >> /tmp/env/topology.json
              sed -i "s/%CSP%/$CSP/g" /tmp/env/init-yb.sh
              sed -i "s/%REGION%/$REGION/g" /tmp/env/init-yb.sh
              sed -i "s/%ZONE%/$ZONE/g" /tmp/env/init-yb.sh
          env:
            - name: K8S_NODE
              valueFrom:
                fieldRef:
                  fieldPath: spec.nodeName
          volumeMounts:
            - name: yb-table-servers
              mountPath: /yb-table-servers
            - name: config-shared-volume
              mountPath: /tmp/env
      containers:
        - name: "yb-tserver"
          image: "yugabytedb/yugabyte:2.6.1.0-b49"
          imagePullPolicy: IfNotPresent
          resources:
            requests:
              cpu: 14000m
              memory: 26Gi
          env:
            - name: POD_IP
              valueFrom:
                fieldRef:
                  fieldPath: status.podIP
            - name: HOSTNAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
          # core dumps are collected to workingDir if
          # kernel.core_pattern is set to a relative path like
          # core.%e.%p.%t ref:
          # https://github.com/yugabyte/charts/issues/11
          workingDir: "/mnt/disk0/cores"
          #command entrypoint is taken from mounted volume written to by init container.
          #init container copies template from configmap yb-table-servers and modifies placeholders
          #for csp, region, and zone
          command:
            - "sh"
            - "-c"
            - |
              /tmp/env/init-yb.sh
          ports:
            - containerPort: 9000
              name: "http-ui"
            - containerPort: 12000
              name: "http-ycql-met"
            - containerPort: 11000
              name: "http-yedis-met"
            - containerPort: 13000
              name: "http-ysql-met"
            - containerPort: 9100
              name: "tcp-rpc-port"
            - containerPort: 6379
              name: "tcp-yedis-port"
            - containerPort: 9042
              name: "tcp-yql-port"
            - containerPort: 5433
              name: "tcp-ysql-port"
          volumeMounts:
            - name: datadir0
              mountPath: /mnt/disk0
            - name: datadir1
              mountPath: /mnt/disk1
            - name: config-shared-volume
              mountPath: /tmp/env
        - name: yb-cleanup
          image: "busybox:1.32"
          env:
            - name: USER
              value: "yugabyte"
          command:
            - "/bin/sh"
            - "-c"
            - >
              mkdir /var/spool/cron;
              mkdir /var/spool/cron/crontabs;
              echo "0 * * * * /home/yugabyte/scripts/log_cleanup.sh" | tee -a /var/spool/cron/crontabs/root;
              crond;
              while true; do
                sleep 86400;
              done
          volumeMounts:
            - name: datadir0
              mountPath: /home/yugabyte/
              subPath: yb-data
      volumes:
        - name: config-shared-volume
          emptyDir: {}
        - name: yb-table-servers
          configMap:
            name: yb-table-servers
            defaultMode: 0755
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: "yb-tserver-spot"
  namespace: "yugabyte"
  labels:
    app: "yb-tserver"
spec:
  serviceName: "yb-tservers"
  podManagementPolicy: Parallel
  replicas: 3
  volumeClaimTemplates:
    - metadata:
        name: datadir0
      spec:
        accessModes: [ "ReadWriteOnce" ]
        resources:
          requests:
            storage: 100Gi
    - metadata:
        name: datadir1
      spec:
        accessModes:
          - "ReadWriteOnce"
        resources:
          requests:
            storage: 100Gi
  updateStrategy:
    type: RollingUpdate
    rollingUpdate:
      partition: 0
  selector:
    matchLabels:
      app: "yb-tserver"
  template:
    metadata:
      labels:
        app: "yb-tserver"
        scheduling.cast.ai/spot-reliability: "5"
    spec:
      serviceAccountName: nodereader
      tolerations:
        - key: scheduling.cast.ai/spot
          operator: Exists
      nodeSelector:
        scheduling.cast.ai/spot: "true"
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            - labelSelector:
                matchExpressions:
                  - key: app
                    operator: In
                    values:
                      - "yb-tserver"
              topologyKey: "kubernetes.io/hostname"
      initContainers:
        - name: init-topology
          image: "photon:3.0-20210108"
          imagePullPolicy: IfNotPresent
          command:
            - "sh"
            - "-c"
            - |
              cp /yb-table-servers/init-yb.sh /tmp/env/init-yb.sh
              curl -L'#' -o /usr/bin/jq https://github.com/stedolan/jq/releases/download/jq-1.5/jq-linux64 && chmod +x /usr/bin/jq
              export CSP="AWS"
              export REGION=$(curl -sv --cacert /var/run/secrets/kubernetes.io/serviceaccount/ca.crt -H "Authorization: Bearer $(cat /var/run/secrets/kubernetes.io/serviceaccount/token)" https://$KUBERNETES_PORT_443_TCP_ADDR:$KUBERNETES_PORT_443_TCP_PORT/api/v1/nodes/$K8S_NODE | jq '.metadata.labels."topology.kubernetes.io/region"')
              export ZONE="on-spot"
              echo "{ \"csp\":$CSP, \"region\":$REGION, \"zone\":$ZONE }" >> /tmp/env/topology.json
              sed -i "s/%CSP%/$CSP/g" /tmp/env/init-yb.sh
              sed -i "s/%REGION%/$REGION/g" /tmp/env/init-yb.sh
              sed -i "s/%ZONE%/$ZONE/g" /tmp/env/init-yb.sh
          env:
            - name: K8S_NODE
              valueFrom:
                fieldRef:
                  fieldPath: spec.nodeName
          volumeMounts:
            - name: yb-table-servers
              mountPath: /yb-table-servers
            - name: config-shared-volume
              mountPath: /tmp/env
      containers:
        - name: "yb-tserver-spot"
          image: "yugabytedb/yugabyte:2.6.1.0-b49"
          imagePullPolicy: IfNotPresent
          resources:
            requests:
              cpu: 14000m
              memory: 26Gi
          env:
            - name: POD_IP
              valueFrom:
                fieldRef:
                  fieldPath: status.podIP
            - name: HOSTNAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
          # core dumps are collected to workingDir if
          # kernel.core_pattern is set to a relative path like
          # core.%e.%p.%t ref:
          # https://github.com/yugabyte/charts/issues/11
          workingDir: "/mnt/disk0/cores"
          #command entrypoint is taken from mounted volume written to by init container.
          #init container copies template from configmap yb-table-servers and modifies placeholders
          #for csp, region, and zone
          command:
            - "sh"
            - "-c"
            - |
              /tmp/env/init-yb.sh
          ports:
            - containerPort: 9000
              name: "http-ui"
            - containerPort: 12000
              name: "http-ycql-met"
            - containerPort: 11000
              name: "http-yedis-met"
            - containerPort: 13000
              name: "http-ysql-met"
            - containerPort: 9100
              name: "tcp-rpc-port"
            - containerPort: 6379
              name: "tcp-yedis-port"
            - containerPort: 9042
              name: "tcp-yql-port"
            - containerPort: 5433
              name: "tcp-ysql-port"
          volumeMounts:
            - name: datadir0
              mountPath: /mnt/disk0
            - name: datadir1
              mountPath: /mnt/disk1
            - name: config-shared-volume
              mountPath: /tmp/env
        - name: yb-cleanup
          image: "busybox:1.32"
          env:
            - name: USER
              value: "yugabyte"
          command:
            - "/bin/sh"
            - "-c"
            - >
              mkdir /var/spool/cron;
              mkdir /var/spool/cron/crontabs;
              echo "0 * * * * /home/yugabyte/scripts/log_cleanup.sh" | tee -a /var/spool/cron/crontabs/root;
              crond;
              while true; do
                sleep 86400;
              done
          volumeMounts:
            - name: datadir0
              mountPath: /home/yugabyte/
              subPath: yb-data
      volumes:
        - name: config-shared-volume
          emptyDir: {}
        - name: yb-table-servers
          configMap:
            name: yb-table-servers
            defaultMode: 0755
